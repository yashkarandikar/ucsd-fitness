use_features = 1
Data matrix dimensions = 9841317 x 5
@E = 10,lam1 = 0.100000,lam2 = 0.000000, lbfgs_max_iterations = 200
U = 83423 , E = 10 , nparams = 834242
Super Iteration 0..Iteration 1: 
@fx = 18737.605352
LBFGS terminated with status -997
Super Iteration 1..Iteration 1: 
@fx = 114.530660
LBFGS terminated with status -997
Super Iteration 2..Iteration 1: 
@fx = 70.891906
LBFGS terminated with status -997
Super Iteration 3..Iteration 1: 
@fx = 57.485116
LBFGS terminated with status -997
Super Iteration 4..Iteration 1: 
@fx = 50.417883
LBFGS terminated with status -997
Super Iteration 5..Iteration 1: 
@fx = 45.891346
LBFGS terminated with status -997
Super Iteration 6..Iteration 1: 
@fx = 43.250249
LBFGS terminated with status -997
Super Iteration 7..Iteration 1: 
@fx = 41.895860
LBFGS terminated with status -997
Super Iteration 8..Iteration 1: 
@fx = 41.082898
LBFGS terminated with status -997
Super Iteration 9..Iteration 1: 
@fx = 40.589346
LBFGS terminated with status -997
Loading data from file..
Doing sorted check on train and val sets..
Number of workouts =  83423
Training set has 9841317 examples
Validation set has 7352229 examples
Training..
Use features =  True
Running command ./predictor_insthr_evolving_cpp data.txt 0.1 0.0 model.txt 10 200 1
Done with learning..
Reading learned model from file..
	Reading E..
	Reading theta..
	Reading sigma..
Loading model..
Assuming last tiredness levels for validation and test sets..
Adding experience levels to data matrices
Making predictions..
1000000 data points done..
2000000 data points done..
3000000 data points done..
4000000 data points done..
5000000 data points done..
6000000 data points done..
7000000 data points done..
8000000 data points done..
9000000 data points done..
1000000 data points done..
2000000 data points done..
3000000 data points done..
4000000 data points done..
5000000 data points done..
6000000 data points done..
7000000 data points done..
1000000 data points done..
2000000 data points done..
3000000 data points done..
4000000 data points done..
5000000 data points done..
6000000 data points done..
7000000 data points done..
{'distance': 2, 'hr': 3, 'workout_number': 0, 'experience': 5, 'workout_id': 1, 'duration': 4}
Computing statistics

@Training Examples = 9841317,MSE = 35.890440,Variance = 454.327908,FVU = 0.078997,R2 = 1 - FVU = 0.921003, E = 10

@Validation Examples = 7352229,MSE = 154.612822,Variance = 348.064883,FVU = 0.444207,R2 = 1 - FVU = 0.555793, E = 10

@Test Examples = 7321065,MSE = 290.639377,Variance = 398.075182,FVU = 0.730112,R2 = 1 - FVU = 0.269888, E = 10

@Total time taken =  676.171305895
[   0.21    0.21    0.21 ...,    0.59  131.78   -1.48]
